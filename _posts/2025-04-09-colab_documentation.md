---
title: "[ë¬¸ì„œê´€ë¦¬]Colab ë…¸íŠ¸ë¶íŒŒì¼ html, pdf, ê³µìœ ë§í¬ ìƒì„± ìë™í™”"
excerpt: ""
toc: true
toc_sticky: true
categories:
- Python
- Colab
- JupyterNotebook
- Documentation
modified_date: 2025-04-09 09:36:28 +0900
---

## ì´ ê¸€ì˜ ëª©ì  
- POCë¥¼ ìì£¼í•˜ë‹¤ë³´ë©´.. Colabì—ì„œ ë…¸íŠ¸ë¶ êµ¬ë™ í›„ ê·¸ ê²°ê³¼ë¥¼ ì†ŒìŠ¤ì½”ë“œ ì—†ì´ ê°„ë‹¨í•˜ê²Œ ì œê³µí•´ì•¼í•˜ëŠ” ìˆœê°„ì´ ì˜¨ë‹¤.
- ê·¸ ë•Œë§ˆë‹¤ ë³´ë ¤ê³  ê¸°ë¡í•¨ 
- ì–»ì„ ìˆ˜ ìˆëŠ” ë‚´ìš©
  - notebookì— ì“´ í…ìŠ¤íŠ¸ ëª©ì°¨ ë„£ì–´ì„œ html ë§Œë“œëŠ” ê²ƒ
  - notebookì—ì„œ ê·¸ë¦° í° ê·¸ë˜í”„ ë”°ë¡œ ê·¸ë¦¼íŒŒì¼ë¡œ ë§Œë“¤ì–´ htmlì— ë„£ëŠ” ê²ƒ
  - pdf ë³€í™˜
  - êµ¬ê¸€ë“œë¼ì´ë¸Œ ë‹¤ìš´ë¡œë“œ ê³µìœ  ë§í¬ ì¶œë ¥

## Pre-requisite 

```sh
!pip install nbconvert
!pip install jupyter_contrib_nbextensions
```

## ìë™í™” ìŠ¤í¬ë¦½íŠ¸ 

```python
import base64
from bs4 import BeautifulSoup
import os

# === ì‚¬ìš©ì ì„¤ì • ===
notebook_input = "/content/drive/MyDrive/hdc_csp/nsquare_keyword.ipynb"
html_output_path = "/content/drive/MyDrive/hdc_csp/nsquare_keyword_final.html"
pdf_output_path = "/content/drive/MyDrive/hdc_csp/nsquare_keyword_final.pdf"
image_file_path = "/content/drive/MyDrive/hdc_csp/voc_wordcloud.png" # ê¼­ htmlê³¼ ê°™ì€ ê²½ë¡œì— ìˆì–´ì•¼í•œë‹¤. 
temp_html_path = "/content/drive/MyDrive/hdc_csp/temp.html"

# === 1ë‹¨ê³„: nbconvert (ì¶œë ¥ ì—†ì´, Google Drive í´ë”ì— ì €ì¥) ===
!jupyter nbconvert --to html --no-input "{notebook_input}" --output "{temp_html_path[:-5]}" > /dev/null 2>&1

# === 2ë‹¨ê³„: temp.html ì—´ê¸° ===
with open(temp_html_path, "r", encoding="utf-8") as file:
    soup = BeautifulSoup(file, "html.parser")

# === 3ë‹¨ê³„: 'Output hidden' í…ìŠ¤íŠ¸ ì‚­ì œ ===
for output_hidden in soup.find_all(string=lambda text: isinstance(text, str) and "Output hidden;" in text):
    output_hidden.extract()

# === 4ë‹¨ê³„: TOC ìƒì„± (h1 > h2 > h3 íŠ¸ë¦¬ êµ¬ì¡° ì™„ì„±) ===
toc_container = soup.new_tag("div", id="toc")
toc_title_tag = soup.new_tag("strong")
toc_title_tag.string = "ğŸ“– ëª©ì°¨"
toc_container.append(toc_title_tag)

toc_list = soup.new_tag("ul")
toc_container.append(toc_list)

header_tags = soup.find_all(["h1", "h2", "h3"])

current_h1 = None
current_h2 = None

for idx, header in enumerate(header_tags):
    if not header.has_attr("id"):
        header['id'] = f"toc_{idx}"

    link = soup.new_tag("a", href=f"#{header['id']}")
    link.string = header.get_text()

    list_item = soup.new_tag("li")
    list_item.append(link)

    if header.name == "h1":
        toc_list.append(list_item)
        current_h1 = list_item
        current_h2 = None
    elif header.name == "h2":
        if current_h1 is None:
            toc_list.append(list_item)
        else:
            if not current_h1.find('ul'):
                current_h1.append(soup.new_tag("ul"))
            current_h1.find('ul').append(list_item)
        current_h2 = list_item
    elif header.name == "h3":
        if current_h2 is not None:
            if not current_h2.find('ul'):
                current_h2.append(soup.new_tag("ul"))
            current_h2.find('ul').append(list_item)
        elif current_h1 is not None:
            if not current_h1.find('ul'):
                current_h1.append(soup.new_tag("ul"))
            current_h1.find('ul').append(list_item)
        else:
            toc_list.append(list_item)

style_tag = soup.new_tag("style")
style_tag.string = """
#toc {
    position: fixed;
    top: 20px;
    right: 20px;
    width: 250px;
    background: #f9f9f9;
    border: 1px solid #ddd;
    padding: 10px;
    max-height: 90vh;
    overflow-y: auto;
    box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    z-index: 1000;
    font-family: sans-serif;
    font-size: 14px;
}
#toc ul {
    list-style: none;
    padding-left: 0;
}
#toc li {
    margin: 5px 0;
}
#toc li ul {
    padding-left: 15px;
}
#toc li ul li ul {
    padding-left: 15px;
}
#toc a {
    text-decoration: none;
    color: #333;
}
#toc a:hover {
    text-decoration: underline;
}
"""
soup.head.append(style_tag)

if soup.body:
    soup.body.insert(0, toc_container)

# === 5ë‹¨ê³„: ì´ë¯¸ì§€ base64 ì‚½ì… (ë¬¸ì„œ ë§¨ ë§ˆì§€ë§‰) ===
with open(image_file_path, "rb") as image_file:
    image_base64 = base64.b64encode(image_file.read()).decode('utf-8')

img_tag = soup.new_tag("img", alt="VOC ì›Œë“œí´ë¼ìš°ë“œ",
                       style="max-width: 100%; height: auto; display: block; margin: 20px auto;",
                       src=f"data:image/png;base64,{image_base64}")

if soup.body:
    soup.body.append(img_tag)

# === 6ë‹¨ê³„: ìµœì¢… HTML ì €ì¥ ===
with open(html_output_path, "w", encoding="utf-8") as file:
    file.write(str(soup))

print(f"ìµœì¢… HTML íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {html_output_path}")

# === 7ë‹¨ê³„: ì¤‘ê°„ íŒŒì¼ ì‚­ì œ ===
os.remove(temp_html_path)

# === 8ë‹¨ê³„: PDF ë³€í™˜ ===
!apt-get -q install -y wkhtmltopdf > /dev/null
!wkhtmltopdf "{html_output_path}" "{pdf_output_path}" > /dev/null 2>&1

print(f"PDF íŒŒì¼ë„ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {pdf_output_path}")

# === 9ë‹¨ê³„: ë‹¤ìš´ë¡œë“œ ë§í¬ ìƒì„± ===
from google.colab import files

print("ë‹¤ìš´ë¡œë“œ ë§í¬ (HTML):")
files.download(html_output_path)

print("ë‹¤ìš´ë¡œë“œ ë§í¬ (PDF):")
files.download(pdf_output_path)

# === 10ë‹¨ê³„: Google Drive ê³µìœ  ë§í¬ ì¶œë ¥ ===
drive_file_id = html_output_path.split('/')[-1]
print(f"Google Drive ê³µìœ  ë§í¬ (HTML): https://drive.google.com/file/d/{drive_file_id}/view?usp=sharing")

pdf_file_id = pdf_output_path.split('/')[-1]
print(f"Google Drive ê³µìœ  ë§í¬ (PDF): https://drive.google.com/file/d/{pdf_file_id}/view?usp=sharing")

```
