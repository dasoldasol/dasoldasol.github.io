## 2-4. Neural Networks-4 ppt
### Contents
- 2p
- 각 항목에 대한 NN이 바뀐다. 

### Regression
- 3p : Sigmoid를 쓰면 y는 0~1이 나온다. 그러면 regression 못푸나???
- 4p
- solution1) 출력값을 0,1로 정규화 
  - 내가 갖고 있는 -100 ~ 100 y를 linear transform해서 0~1 y’로 
  - 그러나 이 방법은 많이 사용하지 않는다. 
- solution2) 그 대신에 활성화함수를 빼고 linear activation function을 사용합니다. 
  - Y=sigmoid(net) 에서 y=net로 그냥 출력해봐요 
  - 주의! Output Layer만 쓰고 Hidden Layer에는 쓰지 않습니다. 
  - 활성화함수는 linear transform -> non linear transfor한다. 이는 hidden layer의 역할. 
  - 출력레이어에서 linear transform을 안써도 되나? : 히든레이어에서 충분히 non linear transform을 충분히 하자. 출력값의 range를 보기 위해서. 
  - 만약 Hidden Layer에서 non linear를 실행하지 않는다면? 
    - 히든 레이어를 두개 사용했지만 히든레이어1에서 Linear activation function을 쓰게 되면 히든 레이어는 존재하지 않는 것과 똑같게 된다. 

### Binary-Class Classification
- 5p
- 이걸 NN으로 학습하려면 문제가 생긴다. 
  - P1, NN은 Real number가 아닌 norminal value(Red, Black, 대전..)를 다루지 못한다.
  - P2, 학습을 위한 에러함수. 선형함수 할때는 Error 함수로 MSE를 썼다. 그런데, classification에서도 MSE를 쓸 수 있을까? 
- 6p P1 해결
- Norminal value에 대해 training data를 preprocessing한다 (0,1로)
- Binary-Class Classification 함수에서는 활성화함수로 sigmoid를 쓴다. 
  - sigmoid는 0,1이 나오는 함수. 
  - 우리는 0,1이 나오면 된다.(red 1 black 0)
- 7p P2
- sigmoid와 MSE를 같이 사용하지 않는다. 활성화함수의 시그모이드함수와 에러함수로 MSE를 사용하는 것은 안된다. NN이 학습이 되지않는 운이 나쁜 상태가 발생합니다. 
- MSE의 작동방식 : (타겟값-출력값)을 최소화하는 것. 
- 8p P2 해결
- MSE가 아니라 에러함수로 Cross Entropy를 사용하면 된다. 
- 9p 왜 sigmoid랑 MSE같이쓰면안될까 intro - reminding
- 10p 왜 sigmoid랑 MSE같이쓰면안될까 intro - reminding
- 노란색 값 : sigmoid를 미분한 값 
- t=1인데 y=0인 경우를 가정해보자. (뉴럴넷이 아주 반대로 알고있는 경우) 이 경우 학습이 되어야하고 gradient가 나와야한다. gradient를 구해보면 -(1-0)0(1-0) = 0!! 학습이 안되게 된다. MSE의 미분값이 (t-h)
- 다시말해서 활성화함수를 시그모이드를 쓰고 MSE를 쓸경우, NN의 결과가 완전히 반대로 나오는 경우 학습이 안된다. 
- 12p 교차엔트로피
- 반대로 알고 있는 경우 : 델타의 값에(gradient) t=1 y=0을 대입시에 1(1-0)+(1-1)0 = 1로 gradient가 살아있다. 
- 제대로 알고 있는 경우 : t=1 y=1 t=0 y=0인경우 0이 나온다. NN이 제대로 알고 있다는 것이고 update할 필요 없다는 것.
- 13p 크로스엔트로피:확률을 극대화한다
- 로지스틱 회귀분석을 이해하면 편하다. 
  - 개 1이고 고양이 0이라고 정하고 NN을 돌렸더니 출력값이 0.7이 나왔다. 그러면 우리는 개라고 해석한다. (MSE관점에서 해석한것. 타겟값 - 출력값의 거리가 가까운 것으로 해석) 
  - 확률로 해석하면 어떨까. 개일 확률이 0.7이다. 
- 크로스 엔트로피는 뉴럴넷에서 나오는 출력값을 확률로 이해한것. 
  - RED 개 BLUE 고양이 일떄, 개일떄의 확률을 다 곱하고 * 고양이일때의 확률을 다 곱하면 됨
- 14p 크로스 엔트로피 수식 
- 크로스 엔트로피란 확률을 극대화하는 w를 찾는 것 
- 그런데 max를 찾는건 좀 힘드니까 그 식에 (-)를 붙이고 min을 붙인다. 

### Multi-Class Classification 
- 15p 개념 
- 이제는 2개가 아니고 여러개를 분류해야하는 상황
- 문제 : nominal value를 real number로 매핑해야한다. (Red, Yellow, Blue -> 숫자로)
- 16p Nominal Value 처리하기
- 1, 0.5, 0 으로 정하고 sigmoid함수를 활성화함수로 하면 되지 않나요?
- 17p Nominal Value를 1, 0.5, 0으로 정하면 안좋은 이유 
- 레드를 블루라고 얘기하거나 옐로라고 얘기하거나 둘다 순서없이 별로다. 
- MSE의 관점에서는 1을 0.5라고 말해서 틀리는게 0이라고 말해서 틀리는게 더 낫다 라는 그런 암묵적인 규칙이 생겨버린다. Linear 매핑을 한다면..
- 18p 출력을 쪼갠다 
- 출력을 one hot encoding으로 바꿔준다. 
  - one hot encoding : 1이 한개가 있는 값으로 변화시키기. 
- output의 개수는 class의 개수와 같다.(R, Y, B)
- 출력이 0,1이기 떄문에 활성화함수는 교차엔트로피를 쓴다. 
- 노란색 hmm : 근데 바이너리랑 교차엔트로피 모양이 달라요? 
- 19p multi class를 위한 교차 엔트로피 
- 바이너리 클래스도 멀티 클래스니까 세번째거처럼 변경해보자. output을 2개 두기. (1,0) (0,1) 
- 출력 노드가 2개 생기니까 출력에서 각 출력노드의 크로스엔트로피를 더한다. 
- 출력 1개일때 : 똑같은 트레이닝 데이터에 1이 나온다면 / 출력 2개일때 : 데이터는 1,0이 나온다.     
이를 대입해보면 (1 ?)(1-1 * (?)) 이 식과  (1 ?)+ 0 * ? 이 식은 동등하게 되다 
- 20p activation function
- 멀티 클래스 분류에서는 활성화함수에서 시그모이드를 사용하지 않고 소프트맥스 함수를 씁니다. 
- 멀티 클래스 분류에서는 타켓 값을 다 더하면 1이 된다.
- 그러나 시그모이드를 쓰면 위의 조건이 안맞춰진다. 
- 그래서 우리는 소프트맥스 레이어를 씁니다. 
- 21p softmax layer 
- regular layer에서는 : net -> activation function -> 출력
- softmax layer에서는 : net -> exp -> normalize -> 출력
- 모든 tn값을 다 더하면 1이 되는 것처럼, 나오는 출력값을 다 더하면 1이 되도록 정규화를 하자. 
- exponential 왜 쓰나요? : 그렇게하면 수학적 성질이 더 좋아져서요.. classification은 크로스엔트로피를 쓰고 이는 확률 기반이다. 모든 트레이닝 데이터에 대해 NN이 맞출 확률을 다 곱한다. 이걸 뭘 어떻게 하면 exp가 들어간다. 
- 22p multi class Error Function 
- 에러함수로는 교차엔트로피 사용. 
- 정리하자면 
  - input을 one hot encoding으로 nominal value 정리하고 
  - output은 softmax 쓰고 
  - error함수는 교차엔트로피 씁니다. 
- 23p multi-class vs. multi-lavel
- multi-class : output 1 가질수있는 value 여러개
- multi-label : output 여러개 
  - (x11 x12 1 1 1 ), (x21 x22 0 1 1) 이렇게 되는 건데. multi class와 뭔 차이가 있나요? : multiclass는 다 더하면 1입니다. multi label은 다 더하면 1이라는 조건이 없습니다. 
- 24p 그래서 multi label은 output layer에 sigmoid 써도 됩니다. 다 더하면 1이 되어야한다는 조건이 없기 떄문에 
- 25p multi label은 일반 regular layer에 sigmoid 쓰고 Loss Function은 교차 엔트로피 씁니다. 
- 출력값은 독립의 output이기 때문에 (독립적인 binary class가 여러개) 각기의 크로스 엔트로피를 죄다 더한 것을 NN의 에러로 정의를 해서 학습을 시켜야한다. 

### Nominal Inputs
- 26p
- one hot encoding 으로 변환해서 사용한다 

## 3-1. Gradient Descent Optimizer

### Stochastic Gradient Descent Methods
- p3 speedup하는 법이 필요하다 : Error Back Propagation
- 업데이트하는데 계산량이 너무 많다. speedup하기 위한 트릭이 필요 
- p4 **Batch Gradient Descent Method**
- 지금까지 우리가 했던것은 Batch Gradient Descent Method
- p5 Batch Gradient Descent Method
- 우리가 지금까지 했던 한 세트를 살펴보면 트레이닝 데이터의 에러에 대한 gradient의 집합이다
- p6-8 why not?
- 그러면 첫번째 트레이닝 데이터의 에러에 대한 gradient가 나오면 바로 업데이트해보자.
- 수학적으로 correct하지는 않음. 트레이닝데이터 수만큼 n번 업데이트가 일어남.(누적해서 1번 업데이트하는게 아니라)
- 근사값을 99번 try하는 게 더 낫다라는 concept.
- p9 
- 에러함수 그래프를 보면 수학적으로 correct하지않아서 삐죽삐죽하지만 어쨌든 우하향하고있다. 시간에 대한 최적화 성능은 더 좋다. 
- batch 로 찾거나 SGD로 찾거나 둘다 똑같이 global optimum이 아니라 local optimum을 찾기 때문에 비교 불가 
- p11-12 mini batch gradient descent method
- 트레이닝 데이터 하나만 보면 좀 그러니까 조금씩 묶어서 가자. 
- 모집단이 있고 샘플을 얻어낸 후 평균분산을 구하는 것과 같다 
- 트레이닝 데이터 전체에 대한 gradient를 구하고 싶은데, 몇개 샘플링하고 샘플의 gradient를 전체의 gradient로 보자는 것. 배치 사이즈 = 샘플 사이즈. population의 크기에 따라 sample(mini batch)의 크기가 달라진다.
- p14 SGD 장점/단점
- 장점 : 좋은 추측, 성능 
- 단점 : 데이터셋트가 variance가 큰 경우 정확도 떨어지미 

### Better Gradient Descent Method
- p15. better gradient descent 
- gradient descent 고민
  - local optimum에서 더 관성을 줘서 탈출하는 방법은 없을까? : 그래서 나온 개념이 Momentum
- 학습률 고민
  - 학습초기에는 크면 좋지만 학습후반에는 작으면 좋은데 지금은 다 고정되어있네
  - 학습시킬때는 모든 가중치가 동등하게 학습될거라고 생각하는데, 학습한 후에 델타(변화)를 보면, 어떤 가중치는 변화가 크고, 어떤 가중치는 작다. 
  - 각 가중치가 경사가 달라서 학습이 잘 안됐을 수도 있다. 
  - 그래서 각기 다른 학습률을 주고 싶다. (gradient가 큰곳은 학습률을 작게, 작은곳은 학습률을 크게 주고 싶다)
- p16 Momentum 
- 단순경사하강법은 현재 위치에 멈춰버린다. 티코가 껌밟은것처럼.. 기울기타고 내려오다보면 모멘텀 받아서 슝 넘어가야하지않는가?
- local optimum을 빠져나가지 못한다. 
- 현재 포인트에 대해서만 gradient가 나오니까 기울기가 크면 팍 점프하고 작으면 작게 점프 (oscilliation 진동의 문제도 있음)
- p17 momentum의 컨셉
- 과거에 움직이던 방향으로 더 간다는 관성의 concept을 넣어준다
- gradient를 구한다 -> 현재 gradient와 과거에 움직이던 방향의 벡터를 구해서 움직인다. 
- 이로써 local mininum에 빠지지 않을 수 있다. 
- p18 momentum 
- 모멘텀 = 과거의 업데이트분량 + 현재지점의 gradient
- p19 momentum 수식 
- rate : 각 모멘텀과 그래디언트를 얼마만큼의 비율로 더할것인가
- p20 모멘텀 장점
- m은 recursive : 나의 이동히스토리에 dependent. 
- m은 과거에 대한 exponential(지수) 평균 : 먼 과거에는 감마가 많이 곱해져서 작아지니까. 
- m은 과거에 대한 평균 : 비슷한 간격으로 가게 되고, 진동이 줄어듭니다. 학습의 속도 향상. 수렴을 더 빨리 한다. 좌충우돌하지 않기 때문에. 
- p21 모멘텀 단점 
- 업데이트 너무 많아. 너무 많이 점프해서 찾고자 하는 포인트를 놓칠 수 있음 
- p22-23 NAG(Nesterov Accelerated Gradient)
- 모멘텀의 변형
- 1step m만 이용해서 점프 -> 2step 점프한 자리에서 gradient를 구한다음에 점프 
